\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{graphicx}
\newcommand{\dhi}{\delta_{\rm HI}}
\newcommand{\nv}{\hat{\bf n}}
\newcommand{\mv}{\hat{\bf m}}
\newcommand{\xpr}{x_\parallel}
\newcommand{\xpp}{{\bf x}_\perp}

%opening
\title{Science-driven optimal binning schemes for photometric redshift surveys and 3D data compression}
\author{}

\begin{document}

\maketitle

A common method to draw cosmological constraints from the clustering of galaxies as measured by a photometric redshift surveys is to divide the galaxy sample into tomographic redshift bins and use the information encoded in all the relevant auto- and cross-correlations between different bins, making use of various calibration methods in order to estimate the true redshift disitribution of each bin. Several criteria can be followed in order to select these redshift bins, such as minimising the correlation between non-neighbouring bins or preserving a roughly constant number density on all bins. Here we present a formalism to determine an optimal scale-dependent binning scheme based on maximizing the amount of cosmological information.

\section{Tomographic galaxy clustering}
  Let us start by assuming that we have split the galaxy sample into $N_s$ subsamples. As mentioned above, we will think of each of these subamples as some kind of redshift binning (e.g. binning galaxies in terms of their maximum-likelihood redshift), but the formalism applies to any set of subsamples. Let $f^\alpha(\nv)$ be the a field on the sphere at the angular position $\nv$ and defined in terms of the properties of the sources in the $\alpha$-th sample (e.g. the cosmic shear field $\gamma^\alpha$ or the galaxy overdensity $\delta^\alpha$), and let $\phi^\alpha(z)$ be the redshift distribution of sources in the sample. Finally, let $a^\alpha_{\ell m}$ be the spherical harmonic coefficients of $f^\alpha$\footnote{Spin-2 fields, such as the cosmic shear, will be decomposed in spin-2 spherical harmonics, however the discussion below holds for this case too}. The power spectrum for our set of subsamples is defined as the two-point correlator of $a^\alpha$:
  \begin{equation}
    \left\langle {\bf a}_{\ell m}\,{\bf a}^\dag_{\ell' m'} \right\rangle\equiv\delta_{\ell\ell'}\delta_{mm'}{\sf C}_\ell,
  \end{equation}
  where we have packaged $a^\alpha$ as a vector for each $(\ell,m)$: ${\bf a}_{\ell m}\equiv(a^1_{\ell m},...,a^{N_s}_{\ell m})$. In general, the observed field will receive contributions from the true cosmological signal (${\bf s}$) and measurement noise (${\bf n}$). Assuming both components are uncorrelated, the same split applies in the power spectrum:
  \begin{equation}
    {\sf C}={\sf S}+{\sf N},\hspace{12pt}
    {\sf S}\equiv\left\langle{\bf s}\,{\bf s}^\dag\right\rangle, \hspace{12pt}
    {\sf N}\equiv\left\langle{\bf n}\,{\bf n}^\dag\right\rangle.
  \end{equation}
  
  Once the choice of subsamples $\alpha$ is chosen, the standard analysis method would then proceed by performing a likelihood evaluation of the two-point statistics of these subsamples. While this procedure is relatively simple, it suffers from a number of drawbacks:
  \begin{enumerate}
   \item It is not clear what the optimal strategy should be to define the sub-samples. One could make sure to exploit all of the information present in the data by using a large number of very narrow redshift bins, and let the likelihood evaluation pick up the information encoded in them. This is however impractical for several reasons.
   \item $C^{\alpha\beta}_\ell$ is a $N_s\times N_s\times N_\ell$ data vector. Thus increasing $N_s$ will increase the computational time required for each likelihood evaluation like $N_s^2$ and number of elements of the covariance matrix of $C^{\alpha\beta}_\ell$ like $N_s^4$, with the corresponding increase in complexity needed to estimate this covariance. Although this can be partially alleviated by considering only correlations between neighbouring redshift shells, the amount of information lost by ditching all correlations beyond a given neighbouring index is not clear in a general setting.
   \item Estimating the redshift distribution for a large number of subsamples can be inaccurate, depending on the method used to do so, on the quality of the photometric redshift posterior information and on the statistics of the spectroscopic sample.
  \end{enumerate}
  
  \subsection{The Karhunen-Loeve basis}
    The idea of the method considered here is to form a small number of linear combinations of the data distributed in narrow redshift bins designed to contain the maximum amount of cosmological information. This can be expressed as a generic Karhunen-Loeve eigenvalue problem (e.g. see \cite{1997ApJ...480...22T} for details), and the procedure to determine the coefficients of these linear combinations is relatively simple:
    \begin{enumerate}
      \item We start by assuming that the field ${\bf a}$ has been measured in a number of narrow redshift bins, and by defining the inverse-variance weighted field $\tilde{\bf a}_{\ell m}\equiv{\sf N}^{-1}_\ell\,{\bf a}_{\ell m}$.
      \item Let us consider a (possibly $\ell$-dependent) set of linear combinations of the weighted field measured on narrow redshift bins:
      \begin{equation}
        {\bf b}_{\ell m}={\sf E}_\ell\cdot\tilde{\bf a}_{\ell m}\equiv{\sf E}_\ell\circ{\bf a},
      \end{equation}
      where ${\bf E}_\ell$ is a yet-unspecified matrix and we have defined the non-standart dot product: ${\bf v}^\dag_\ell\circ{\bf w}_\ell\equiv{\bf v}^\dag_\ell\cdot{\sf N}^{-1}_\ell\cdot{\bf w}_\ell$
      The power spectrum for this new observable would then simply be given by:
      \begin{equation}
        {\sf D}_\ell\equiv\left\langle{\bf b}_{\ell m}\,{\bf b}^\dag_{\ell m}\right\rangle={\sf E}_\ell^\dag\circ{\bf C}_\ell\circ{\sf E}_\ell.
      \end{equation}
      
    \item Let us now find the set of orthonormal vectors ${\bf v}^p_\ell)$ (with ${\bf v}^{p\dag}\circ{\bf v}^q=\delta^{pq}$) that diagonalize the cross-shell power spectrum ${\sf C}_\ell$\footnote{Note that this can always be found also in the case of non-standard dot products. Let ${\sf P}$ be the matrix defining the product, and ${\sf P}={\sf L}{\sf L}^T$ its Cholesky decomposition. The problem of diagonalizing a symmetric matrix ${\sf A}$ with respect to this product is equivalent to diagonalizing ${\sf A}'\equiv{\sf L}^T{\sf A}{\sf L}$ with the standard dot product and multiplying the resulting eigenvectors by $\left({\sf L}^T\right)^{-1}$.}. We then identify $({\sf E}_\ell)^p_\alpha$ with the elements of ${\bf v}^p(\ell)$. Note that, after this transformation and without any further optimization, some of the practicalities of the original problem the original problem are already simplified, since we can now focus on the diagonal elements of the new power spectrum and its covariance.
    \item Let's assume that we are interested in measuring a set of cosmological parameters $\Theta\equiv\{\theta_1,...\}$. The information regarding this set of parameters encoded in a given data vector ${\bf x}$ can be quantified in terms of its Fisher matrix (the Hessian of the log-likelihood with respect to $\Theta$), which assuming $\langle{\bf x}\rangle=0$ reads
    \begin{equation}
      F_{ij}\equiv\left\langle\partial_i\partial_j{\cal L}\right\rangle=\frac{1}{2}{\rm Tr}\left(\partial_i{\sf X}\,{\sf X}^{-1}\partial_j{\sf X}\,{\sf X}^{-1}\right),
    \end{equation}
    where ${\sf X}\equiv\langle {\bf x}{\bf x}^T\rangle$ is the covariance matrix of the data. Since the power spectrum of ${\sf b}$ defined above is diagonal, this expression gets simplified further, and the Fisher matrix can be decomposed into the independent contributions of each mode:
    \begin{equation}
      F_ij=\sum_p F^p_{ij},\hspace{12pt}
      F^p_{ij}\equiv\sum_\ell\frac{2\ell+1}{2}\,(\partial_i\log D^p_\ell)\,(\partial_j\log D^p_\ell)
    \end{equation}
    Thus we can rank the eigenvectors $({\sf E}_\ell)^p_\alpha$ in terms of their information content (in a Fisher-matrix sense).
    \item We then truncate the number of modes to analyze to the first $M$ eigenmodes thus defined, which should therefore contain the bulk of the information needed to constrain $\Theta$.
  \end{enumerate}
  This strategy therefore allows one to reliably and significantly reduce the dimensionality of the data vector from $N_s^2\times N_\ell$ to $M\times N_\ell$ while minimising the loss of information. Note that, although the method is based on an initial thin-slicing of the galaxy distribution, the fact that the final datased comprises only a small set of samples means that the method is not penalized in terms of photometric redshift uncertainties. The same methods used to calibrate these uncertainties in the standard analysis hold in this case with slight modifications (e.g. weighed and $\ell$-dependent stacking of photo-$z$ pdfs, or cross-correlations of the weighed maps with a spectroscopic survey in the case of clustering redshifts).
  
  \subsection{The harmonic-bessel basis}
    Let us consider a simplified case where $f$ is the overdensity field of a non-evolving galaxy population for which, furthermore, and for which we neglect the effect of redshift-space distortions. Let us further assume that we have perfect redshift information, such that we can split the sample into thin radial slices of equal width $\delta \chi$, which we label by their comoving radius $\chi$. The noise in the measurement of $f$ is given purely by shot noise, and since (as per our initial assumptions) the number density of sources does not change with $r$, the noise power spectrum is diagonal and scales like 
    \begin{equation}
      N_\ell(r,r')\propto \frac{\delta_{r,r'}}{r^2}.
    \end{equation}
    Thus, the dot product is just given by:
    \begin{equation}
      {\bf b}^\dag\circ{\bf c}\propto\int dr\,r^2\,b(r)^*\,c(r).
    \end{equation}
    
    In this case, the cross-shell power spectrum is given by,
    \begin{equation}
      C_\ell^{rr'}=\frac{2}{\pi}\int_0^\infty dk\,k^2\,P_k\,j_\ell(kr)j_\ell(kr'),
    \end{equation}
    and it is trivial to show that the K-L eigenmodes are simply given by the spherical Bessel functions: $({\sf E}_\ell)^k_r\propto \sqrt{2/\pi}j_\ell(kr)$:
    \begin{align}
      D_\ell^{kk'}&\propto\frac{2}{\pi}\int dr\,r^2\int dr'\,r'^2 j_\ell(kr)j_\ell(k'r') C_\ell^{rr'}\\
      &=\int dq\,q^2P_q\left[\frac{2}{\pi}\int dr\,r^2\,j_\ell(qr)j_\ell(kr)\right]\left[\frac{2}{\pi}\int dr'\,r'^2\,j_\ell(qr')j_\ell(k'r')\right]\\
      &=\int dq\,q^2P_q\frac{\delta(k-q)}{q^2}\frac{\delta(k'-q)}{q^2}=P_k\frac{\delta(k-k')}{k^2}=\frac{P_k}{k^2\Delta k}\delta_{k,k'}
   \end{align}
   
   This choice of basis defines the so-called harmonic-Bessel decomposition, and has been postulated as a possible data-compression method for the analysis of photometric redshift data (CITES here). In any realistic scenario (e.g. in the presence of redshift uncertainties, RSDs or for the analysis of weak lensing data), this basis is, however, non-optimal in terms of information loss, as opposed to the K-L basis described above.

\section{Particular examples}
  \subsection{Weak lensing - K-L basis for dark energy}
    To quantify the performance of the K-L modes for weak lensing we study the case of an LSST-like survey. The survey specifications and the characteristics of the galaxy sample are described in detail in CITE. In summary, we assume a sample with $\sim29$ objects per ${\rm arcmin}^2$ with the redshift distribution shown in Figure FIG. We also approximate the photo-$z$ distribution as Gaussian with a scatter $\sigma_z=0.05\,(1+z)$.    
    
    The signal part of the cross-power spectrum between the cosmic shear measurements made in two different redshift shells is given by:
    \begin{equation}
      S^{\alpha\beta}_\ell=\frac{2}{\pi}\int_0^\infty dk\,k^2\,\Delta^\alpha_\ell(k)\Delta^\beta_\ell(k),
    \end{equation}
    where the transfer functions $\Delta^{\alpha}_\ell$ take the form:
    \begin{align}
      \Delta^{\gamma,\alpha}_\ell(k)&\equiv\frac{3H_0^2\Omega_M}{2k^2}\sqrt{\frac{(\ell+2)!}{(\ell-2)!}}\int d\chi\,W^\alpha(\chi)\frac{j_\ell(k\chi)}{\chi\,a(\chi)}\sqrt{P(k,z(\chi))},\\
      W^\alpha(\chi)&\equiv\int_{z(\chi)}^\infty dz\,\phi^\alpha(z)\frac{\chi(z')-\chi}{\chi(z')\chi}.
    \end{align}
    Here $\phi^\alpha(z)$ is the redshift distribution of sources in the $\alpha$-th bin. The noise power spectrum is white and simply given by the intrinsic ellipticity scatter weighed by the number density of sources in each redshift bin $\bar{n}^\alpha$:
    \begin{equation}
      N^{\alpha\beta}_\ell=\delta_{\alpha\beta}\frac{\sigma_\gamma^2}{\bar{n}^\alpha},
    \end{equation}
    with $\bar{n}^\alpha$ in units of ${\rm srad}^{-1}$. We use $\sigma_\gamma=0.28$.
    
    As our initial set of narrow redshift bins, we select top-hat bins in photo-$z$ space for $z_{\rm ph}>0.5$ with a width given by the value of $\sigma_z/2$ at the center of the bin. The resulting set of 33 bins is shown in Figure FIG. The large overlap between bins implies that a thinner slices is unlikely to unveil significantly more information (an assumption that we verify below). The lensing auto-power spectra (both signal and noise) for these bins are shown in the left panel of Figure FIG.
    
    We compute the K-L modes for this setup and rank them according to their information content on the dark energy equation of state $w$. The diagonal power spectra for the resulting set of modes is shown in the right panel of  Figure FIG.  Comparing against the left panel of the same figure we can see that the K-L decomposition effectively separates the signal-dominated and noise-dominated modes. The fractional contribution of each mode to the total constraint on $w$ (i.e. its contribution to the corresponding Fisher matrix element) is shown in the left panel of Figure FIG. Most of the information ($\sim95\%$) is contained within a single mode, and the first two modes are able to recover more than $99\%$ of the total. The eigenvectors corresponding to the first mode for different values of $\ell$ are shown in the right panel of the same Figure. The eigenvector upweights the parts of the redshift range with the highest signal-to-noise penalising the low-$z$ regime due to its poor lensing signal and the high-$z$ bins due to their high shot noise.


  \subsection{Galaxy clustering - measuring $f_{\rm NL}$}x
   different forms depending on the nature of $f$:
  \begin{itemize}
    \item Galaxy clustering:
          \begin{equation}
            \Delta^{\delta,\alpha}_\ell(k)\equiv\int dz\,\phi^\alpha(z)\left[b^\alpha(z)j_\ell(k\,\chi(z))-f(z)j_\ell''(k\,\chi(z))\right]\,\sqrt{P(k,z)}
          \end{equation}
    \item Galaxy shear:
          \begin{align}
            \Delta^{\gamma,\alpha}_\ell(k)&\equiv\frac{3H_0^2\Omega_M}{2k^2}\sqrt{\frac{(\ell+2)!}{(\ell-2)!}}\int d\chi\,W^\alpha(\chi)\frac{j_\ell(k\chi)}{\chi\,a(\chi)}\sqrt{P(k,z(\chi))},\\
            W^\alpha(\chi)&\equiv\int_{z(\chi)}^\infty dz\,\phi^\alpha(z)\frac{\chi(z')-\chi}{\chi(z')\chi}
          \end{align}
  \end{itemize}
  Here $b^\alpha(z)$ is the galaxy bias and $f(z)\equiv d\log\delta/d\log a$ is the growth rate of structure (we have kept the contribution from redshift-space distortions at linear order but ignored the effect of magnification bias).
  
\section{Pseudo-$C_\ell$ estimation of the K-L modes}
  One of the standard methods to estimate the angular power spectrum of any two quantities in the cut sky is the so-called pseudo-$C_\ell$ estimator. This section adapts this method to the modes resulting from the K-L decomposition described before.
  
  The standard pseudo-$C_\ell$ method is based on computing the spherical harmonic coefficients of the mask field:
  \begin{equation}
    \tilde{a}^\alpha_{\ell m}=\int d\nv a^\alpha(\nv)w^\alpha(\nv),
  \end{equation}
  where $w^\alpha$ is the weights map characterizing the mask of the field $a^\alpha$. One then estimates the power spectrum of this object by averaging over $m$ for each $\ell$:
  \begin{equation}
    \tilde{C}^{\alpha\beta}_\ell\equiv\frac{\sum_m\tilde{a}^\alpha_{\ell m}\tilde{a}^{\beta *}_{\ell m}}{2\ell+1}.
  \end{equation}
  This object is then related to the true underlying power spectrum through a mode-coupling matrix $M^{\alpha\beta}_{\ell\ell'}$ such that
  \begin{equation}
    \tilde{C}^{\alpha\beta}_\ell=\sum_{\ell'}M^{\alpha\beta}_{\ell\ell'}C^{\alpha\beta}_{\ell'},\hspace{12pt}
    M^{\alpha\beta}_{\ell \ell'}\equiv\sum_{\ell''}\frac{(2\ell'+1)(2\ell''+1)}{4\pi}W^{\alpha\beta}_{\ell''}
    \left(
    \begin{array}{ccc}
      \ell & \ell' & \ell''\\
      0 & 0 & 0
    \end{array}
    \right)^2
  \end{equation}
  where the coupling matrix $M$ depends solely on the power spectrum of the masks $W^{\alpha\beta}_\ell\equiv(2\ell+1)^{-1}\sum_mw^\alpha_{\ell m}w^{\beta *}_{\ell m}$.
  
  The extension of this estimator to the power spectrum of the K-L modes is straightforward: we project the masked harmonic coefficients $\tilde{a}^\alpha$ over the K-L eigenvectors ${\sf E}$ (i.e. $\tilde{\bf b}_{\ell m}\equiv {\sf E}_\ell\circ\tilde{\bf a}_{\ell m}$) and compute their power spectra by averaging over $m$. The resulting estimator takes the form $\tilde{D}^p_\ell=\sum_{\ell'}M_{\ell\ell'}^{pp'}D^{p'}_{\ell'}$, where the new mode-coupling matrix is given by:
  \begin{equation}
    M^{pp'}_{\ell\ell'}\equiv M^{\alpha\beta}_{\ell\ell'}\left[({\sf E}_\ell)^p_\alpha({\sf N}^{-1})_{\alpha\alpha'}({\sf E}_{\ell'})^{p'}_{\alpha'}\right]\left[({\sf E}_\ell)^p_\beta({\sf N}^{-1})_{\beta\beta'}({\sf E}_{\ell'})^{p'}_{\beta'}\right]
    =M_{\ell\ell'}\left[({\sf E}_\ell)^p_\alpha({\sf N}^{-1}_\ell)_{\alpha\beta}({\sf E}_{\ell'})^{p'}_\beta\right]^2
  \end{equation}
  where the second equality holds only if all the maps $a^\alpha_\ell$ share the same mask $w$.\footnote{Note that, for full-sky coverage $M_{\ell\ell'}=\delta_{\ell\ell'}$ and using the orthonormality of ${\sf E}$ we get $M^{pp'}_{\ell\ell'}=\delta_{\ell\ell'}\delta_{pp'}$.}


  
\begin{thebibliography}{12pt}
  \bibitem{1997ApJ...480...22T} Tegmark, M., Taylor, A.~N., \& Heavens, A.~F.\ 1997, ApJ, 480, 22
% \bibitem{Bull:2014rha}
%  P.~Bull, P.~G.~Ferreira, P.~Patel and M.~G.~Santos,
%``Late-time cosmology with 21cm intensity mapping experiments,''
%  Astrophys.\ J.\  {\bf 803} (2015) 1,  21
%  doi:10.1088/0004-637X/803/1/21
%  [arXiv:1405.1452 [astro-ph.CO]].
  %%CITATION = doi:10.1088/0004-637X/803/1/21;%%
  %47 citations counted in INSPIRE as of 14 Feb 2016
% \bibitem{Alonso:2015sfa}
%  D.~Alonso and P.~G.~Ferreira,
  %``Constraining ultralarge-scale cosmology with multiple tracers in optical and radio surveys,''
%  Phys.\ Rev.\ D {\bf 92} (2015) 6,  063525
%  doi:10.1103/PhysRevD.92.063525
%  [arXiv:1507.03550 [astro-ph.CO]].
  %%CITATION = doi:10.1103/PhysRevD.92.063525;%%
  %7 citations counted in INSPIRE as of 14 f√©vr. 2016
\end{thebibliography}

\end{document}
\section{Sampling the density field}
  \subsection{Setup}
    Let us assume a data vector ${\bf d}$ consisting of:
    \begin{itemize}
      \item $\nv$: galaxy positions.
      \item $\mv$: galaxy magnitudes.
    \end{itemize}
    Our main aim is to get samples of the underlying galaxy density field given these data. As we will see, this is most conveniently done while simultaneously sampling the true galaxy redshifts $z_i$. Let ${\bf z}$ be a vector containing all those redshifts and $\delta_g$ an array containing the values of the density field in voxels of volume $v_{\rm vox}$ characterized by their position ${\bf x}$. We want to study the posterior probability $p(\delta_g,{\bf z}|\nv,\mv)$. This can be done by iteratively sampling the two conditional distributions:
    \begin{equation}
      \delta_g^{i+1}\leftarrow p(\delta_g|{\bf z}^i,\nv,\mv),\hspace{12pt}
      {\bf z}^{i+1}\leftarrow p({\bf z}|\delta^{i+1}_g,\nv,\mv),
    \end{equation}
    where:
    \begin{itemize}
      \item The conditional density distribution can be written $p(\delta_g|{\bf z},\nv,\mv)$ 
        \begin{align}
          p(\delta_g|{\bf z},\nv,\mv)&=p(\delta_g|{\bf z},\nv)=p(\delta_g|N_g),
        \end{align}
        where $N_g$ is an array containing the number of objects found in each voxel based on their coordinates $({\bf z},\nv)$. Note that we have used the fact that, if ${\bf z}$ is known, ${\bf m}$ does not add extra information to estimate $\delta_g$.
        
        Now, using Bayes' theorem we can write $p(\delta_g|N_g)\propto p(N_g|\delta_g)p(\delta_g)$. Under the assumption that $N_g$ is a Poisson realization of $\delta_g$ we can
        write:
        \begin{equation}\label{eq:poisson}
          p(N_g|\delta_g)=\prod_{\bf x}\left[\bar{N}_g^{\bf x}(1+\delta_g^{\bf x})\right]^{N_g^{\bf x}}\frac{\exp\left[-\bar{N}_g^{\bf x}(1+\delta_g^{\bf x})\right]}{N_g^{\bf x}!},
        \end{equation}
        where all quantities with a subscript $\,_{\bf x}$ denote the values of the corresponding array at position ${\bf x}$, and $\bar{N}_g^{\bf x}$ is the expected mean number of objects at voxel ${\bf x}$ (e.g. computed from a random catalogue).
        
        Finally, we need a prior $p(\delta_g)$. Assuming a given structure formation model, we could write this prior in terms of the $N$-point statistics of the density field. This would lead us to a maximum-likelihood estimate for these $N$-point functions when additionally sampling over them. Here we will keep things simple by assuming a flat prior on $\delta_g$, and using the samples of  $\delta_g$ to estimate its correlation function.
        
        Thus we obtain that $p(\delta_g|{\bf z},\nv,\mv)$ is simply given by $p(N_g|\delta_g)$ as in Eq. \ref{eq:poisson}. Since Poisson processes are completely uncorrelated, we can take samples of $p(\delta_g|{\bf z},\nv,\mv)$ analytically on a point-by-point basis.
        
      \item Under the assumption that 
      
    \end{itemize}


    
    
    Let us assume that the joint probability is factorizable between clustering and
    spectral information:
    \begin{equation}
      p(\dhi,\nv,\mv,{\bf z})\equiv\pi_\delta(\dhi,\nv,{\bf z})\pi_m(\mv,{\bf z})=
      \frac{p(\dhi,\nv,{\bf z})\,p({\bf z}|\mv)\,p(\mv)}{p({\bf z})}=
      p(\dhi,\nv|{\bf z})\,p({\bf z}|\mv)\,p(\mv),
    \end{equation}
    where all the $p$'s are marginalized over any variable that is not explicitly
    shown. Then the posterior distribution can be written as:
    \begin{equation}
      p({\bf z}|\dhi,\nv,\mv)\propto p(\dhi,\nv|{\bf z})\,p({\bf z}|\mv).
    \end{equation}
    Assuming no correlation between redshifts and angles we can further write:
    \begin{equation}
      p(\dhi,\nv|{\bf z})=p(\dhi|\nv,{\bf z})\,p(\nv|{\bf z})\propto
      p(\dhi|\nv,{\bf z}).
    \end{equation}
    Note that this is not a correct assumption: due to clustering, galaxies that
    are close in redshift will have a higher chance of being close in angle. However,
    we would like to isolate the improvement on the photo-$z$ due to the combination
    with HI from what can be achieved using the data available in the photometric
    survey alone, which is encoded in $p(\nv|{\bf z})$.

    Now, given $\nv$ and ${\bf z}$ one can produce a map of the galaxy overdensity
    field in a deterministic way:
    \begin{equation}
      \{\nv,{\bf z}\}\rightarrow \delta_g=f(\nv,{\bf z}),
    \end{equation}
    where we will write the function $f$ explicitly below in the flat-sky
    approximation. Therefore we can write
    \begin{equation}
      p(\dhi,\nv|{\bf z})\propto p(\dhi|\delta_g(\nv,{\bf z})),
    \end{equation}
    and we find the final form for the posterior distribution:
    \begin{equation}
      p({\bf z}|\dhi,\nv,\mv)\propto p(\dhi,|\delta_g(\nv,{\bf z}))\,p({\bf z}|\mv). 
    \end{equation}
    
    Thus, the posterior for ${\bf z}$ can be understood as coming from a photometric
    prior $p({\bf z}|\mv)$, and a clustering likelihood $p(\dhi|\delta_g)$. Note that,
    due to the high dimensionality of ${\bf z}$ (possibly $\mathcal{O}(10^4-10^5)$
    galaxies), drawing samples from this distribution is a numerically challenging
    problem. However, we will outline a possible method below.
    
\section{Individual redshift estimation}
%  \begin{figure}
%    \centering
%    \includegraphics[width=0.7\textwidth]{pdf_1d.png}
%    \caption{}\label{fig:pdf_1d}
%  \end{figure}
  The formalism described in the previous section uses the full clustering information
  of a sample of galaxies with an overlaping HI map to evaluate the joint posterior
  distribution of all the galaxy redshifts. As we have seen, this is an interesting
  problem from the point of view of data analysis which could potentially improve the
  redshift measurements and which can realistically be solved using efficient sampling
  methods. We have also seen that the resulting joint distribution will potentially be
  multi-modal and show tight correlations between different galaxies. However, this
  formalism is the most general and optimal way of estimating galaxy redshifts in
  the presence of overlapping datasets with good radial information.
  
  In this section we present a simpler (but non-optimal) method, based on inferring 
  the redshifts of individual galaxies from the measured density field along the line
  of sight (i.e. ignoring the full clustering information between the full galaxy sample
  and the HI field).  
  In this case we want to calculate the probability distribution for the redshift of a
  single galaxy given the data:
  \begin{equation}
    p(z|\dhi,\hat{n},m)=p(z|\dhi,\hat{n}) p(m|z)/p(m),
  \end{equation}
  where, as before, we have separated the information coming from magnitudes and
  clustering. We can see that, as before, the information from the photometry $m$
  functions as a prior on $p(z|\dhi,\hat{n})$. For the moment let us focus on
  $p(z|\dhi,\hat{n})$. First, notice that we can read this as $p(z|\dhi(\hat{n}))$,
  the probability for $z$ given the measured ${\rm HI}$ density along the same line
  of sight. On the other hand, the galaxy redshift distribution is determined by
  the true galaxy density field $\delta_g$, which we can consider $\dhi$ to be a
  noisy measurement of. We must therefore sum over all
  realizations of $\delta_g$ compatible with $\dhi$:
  \begin{equation}\label{eq:single_1}
    p(z|\dhi)=\int \mathcal{D}\delta_g\,p(z|\delta_g,\dhi)\,p(\delta_g|\dhi).
  \end{equation}
  Now, since $\delta_{\rm HI}$ is just a noisy measurement of $\delta_g$, we can
  write $p(z|\delta_g,\delta_{\rm HI})\equiv p(z|\delta_g)$. Since the frequentist
  probability distribution for the galaxy redshifts is just proportional to the
  galaxy density field, we can then write $p(z|\delta_g)\propto\rho_g\propto(1+\delta_g)$,
  in which case the conditional distribution in Eq. \ref{eq:single_1} reads
  \begin{align}
    p(z|\dhi)&\propto\int \mathcal{D}\delta_g(1+\delta_g)\,p(\delta_g|\dhi)\\
             &\equiv(1+\langle\delta_g|\dhi\rangle)
  \end{align}

  For Gaussian random fields, it is easy to show that the mean density field
  conditional on the measured values $\delta_{\rm HI}$,
  $\langle\delta_g|\dhi\rangle$, is given by the Wiener-deconvolved overdensity:
  \begin{equation}
    \langle\delta_g|\dhi\rangle=\hat{C}_{g,{\rm HI}}\,
    \hat{C}_{{\rm HI},{\rm HI}}^{-1}\,\dhi,
  \end{equation}
  where $\hat{C}_{a,b}\equiv\langle\delta_a\delta_b^T\rangle$ is the covariance matrix
  between two fields (understood as vectors in this notation). This is more easily
  written in Fourier space
  \begin{equation}
    \left.\langle\delta_g|\dhi\rangle\right|_{\bf k}=\frac{P_{{\rm HI}-g}({\bf k})}
    {P_{{\rm HI}-{\rm HI}}({\bf k})+N_{\rm HI}(\bf k)}\dhi({\bf k}).
  \end{equation}
  
  The process to estimate the redshift distribution for individual galaxies, given
  a measurement of $\delta_{\rm HI}$ is then relatively straightforward:
  \begin{enumerate}
    \item Compute the Wiener-filtered overdensity field
          $\langle\delta_g|\delta_{\rm HI}\rangle$.
    \item Evaluate this field along the line of sight of each galaxy in the sample.
    \item Multiply this ``clustering likelihood'' by the photometric redshift prior
          $p(m|z)$ and normalize the resulting distribution to unity.
  \end{enumerate}

  See an example of this in Fig \ref{fig:pdf_1d}.

  Fisher-matrix estimate of the width of this distribution:
  \begin{equation}
   \frac{1}{\sigma_\parallel^2}=\frac{1}{\sigma_{\rm ph}^2}+
   \left[4\pi\int_{0}^\infty dk_\parallel \left[\frac{k_\parallel}{2\pi}\right]^4\int_0^\infty
   dk_\perp\,k_\perp
   \frac{P_{{\rm HI-HI}}(k_\parallel,k_\perp)P_{g-g}(k_\parallel,k_\perp)}
   {P_{\rm HI-HI}(k_\parallel,k_\perp))+N_{\rm HI}}\right]^{1/2}
  \end{equation}

  \subsection{Explicit expressions in the flat-sky approximation}
    Under the assumption that both $\dhi$ and $\delta_g$ are homogeneous and isotropic
    Gaussian fields, their Fourier modes are statistically independent and completely
    described by their covariance matrix
    \begin{equation}
      \hat{\Sigma}({\bf k})\equiv\left(\begin{array}{cc}
      \langle|\dhi({\bf k})|^2\rangle &
      \langle\dhi({\bf k})\delta_g^*({\bf k})\rangle\\
      \langle\dhi({\bf k})\delta_g^*({\bf k})\rangle &
      \langle|\delta_g({\bf k})|^2\rangle
      \end{array}\right).
    \end{equation}

    In this limit, the likelihood $p(\dhi|\delta_g)$ is most easily written in
    terms of these Fourier modes:
    \begin{align}\label{eq:like_gauss}
      -2\log\left[p(\dhi|\delta_g)\right]&=\sum_{\bf k}\frac{1}{1-\epsilon^2({\bf k})}
      \left|\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-\epsilon({\bf k})
      \frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right|^2
    \end{align}
    where
    \begin{align}
      &\sigma^2_{\rm HI}({\bf k})\equiv\langle|\dhi({\bf k})|^2\rangle=
       \frac{(2\pi)^3}{V}P_{{\rm HI}-{\rm HI}}({\bf k})\\
      &\sigma^2_g({\bf k})\equiv\langle|\delta_g({\bf k})|^2\rangle=
       \frac{(2\pi)^3}{V}P_{g-g}({\bf k})\\
      &\epsilon({\bf k})\equiv\frac{\langle\dhi({\bf k})\delta_g^*({\bf k})\rangle}
       {\sqrt{\langle|\dhi({\bf k})|^2\rangle\langle|\delta_g({\bf k})|^2\rangle}}
       =\frac{P_{{\rm HI}-g}({\bf k})}{\sqrt{P_{{\rm HI}-{\rm HI}}({\bf k})
       P_{g-g}({\bf k})}},\\
      &\langle\delta_a({\bf k})\delta_b^*({\bf k}')\rangle\equiv
      \delta^D({\bf k}-{\bf k}')P_{a-b}({\bf k}).
    \end{align}
    Here $V$ is the volume of the piece of sky where we're trying to estimate the
    redshifts.

    Note that Eq. \ref{eq:like_gauss} follows simply from:
    \begin{equation}
      p(\dhi|\delta_g)=\frac{p(\dhi,\delta_g)}{p(\delta_g)}={\rm exp}
      \left[-\frac{1}{2}\sum_{\bf k}
      \left((\dhi,\delta_g)^\dag\cdot\hat{\Sigma}\cdot(\dhi,\delta_g)-
      \frac{|\delta_g|^2}{\sigma_g^2}\right)\right]
    \end{equation}

  \subsubsection{From positions to density}
    Ultimately we would like to write the likelihood in Eq. \ref{eq:like_gauss} in
    terms of the galaxy angles and redshifts. We will do so here in the flat-sky
    approximation, where we will replace $z$ and $\nv$ with the comoving radial
    and transverse galaxy coordinates, $\xpr$ and $\xpp$.

    Given a set of $N_g$ points characterized by their 3D positions ${\bf x}^p$
    ($p\in[1,N_g]$), they can be interpolated into a number overdensity field
    $\delta_g$ as:
    \begin{equation}
      \delta_g({\bf r}|\{\xpr^p\})=\frac{1}{N_g}\sum_pW({\bf r}-{\bf x}^p)-1,
    \end{equation}
    where $W$ is the kernel used for interpolation (which integrates to 1). For the
    results presented here, the specific choice of kernel is irrelevant. Using this,
    we can express the Fourier coefficients entering Eq. \ref{eq:like_gauss} in
    terms of the galaxy coordinates as
    \begin{align}\label{eq:pos2dens}
       \delta_g({\bf k}|\{\xpr^p\})&=\sum_{\bf r}(\Delta r)^3
       \frac{e^{i{\bf k}{\bf r}}}{(2\pi)^{3/2}}\delta_g({\bf r})\\
      &=-\left(\frac{\Delta r}{\sqrt{2\pi}}\right)^3\sum_{\bf r}e^{i{\bf k}{\bf r}}+
       \sum_p\left(\frac{\tilde{W}({\bf k})}{N_g}e^{i{\bf k}{\bf x}^p}\right),
    \end{align}
    where we have defined the Fourier transform of the interpolation kernel:
    \begin{equation}
      \tilde{W}({\bf k})\equiv\int dr^3 W({\bf r})\frac{e^{i{\bf k}{\bf r}}}
      {(2\pi)^{3/2}}.
    \end{equation}
    
    Note that, given Equations \ref{eq:like_gauss} and \ref{eq:pos2dens}, we can write
    the likelihood as an analytical function of the galaxy redshift (or radial positions
    in this case), and we can thus also evaluate its gradient with respect to ${\bf z}$
    analytically. This would allow us to take samples from it using Hamiltonian Monte-Carlo
    methods (CITES). These methods allow a much more efficient sampling of high-dimensional
    distributions than traditional Markov-chain algorithms, and have been used in Bayesian
    analyses of structure formation for up to $\mathcal{O}(10^7)$ objects.
    
    Although this type of analysis is, therefore, feasible, it would be ideal if we could
    first obtain an order-of-magnitude estimate of improvement in the redshift accuracy one
    could expect from it. We will do so in the next section by attempting a Fisher-matrix
    analysis of the posterior.
  
  \subsubsection{Fisher matrix predictions}
    For simplicity, let us now assume that all galaxies in our sample have the same
    photo-$z$ distribution, given by a Gaussian in $\xpr$ with width
    $\sigma_{\rm ph}$. In that case we obtain the log-posterior distribution:
    \begin{align}\nonumber
       \mathcal{L}\equiv -2\log[p(\{\xpr^p\}|\dhi,\xpp,{\bf m})]&=
       \sum_p\frac{(\xpr^p-\overline{\xpr}^p)^2}{\sigma_{\rm ph}^2}+
       \mathcal{L}_g[\delta_g({\bf k}|\{\xpr^p\})]\\\label{eq:logpos}
      &\equiv\sum_p\frac{(\xpr^p-\overline{\xpr}^p)^2}{\sigma_{\rm ph}^2}+
       \sum_{\bf k}\frac{1}{1-\epsilon^2({\bf k})}
       \left|\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-\epsilon({\bf k})
       \frac{\delta_g({\bf k}|\{\xpr^p\})}{\sigma_g({\bf k})}\right|^2
    \end{align}

    Since the relation between $\delta_g$ and ${\bf x}^p$ is non-linear
    (Eq. \ref{eq:pos2dens}), this posterior expressed in terms of the radial
    positions is non-Gaussian, and therefore difficult to integrate. In
    order to gain some insight into the potential of this method we can,
    however, perform a Fisher-matrix analysis. This is explicitly done in
    Appendix \ref{app:fisher}, obtaining:
    \begin{equation}\label{eq:final_fisher}
      \frac{1}{\sigma_\parallel^2}\simeq
      \frac{1}{\sigma_{\rm ph}^2}+2\int_0^\infty dk_\parallel
      \left[\frac{k_\parallel}{2\pi}\right]^2\int_0^\infty dk_\perp k_\perp
      \frac{P_{\rm HI-HI}(k_\parallel,k_\perp)P_{g-g}(k_\parallel,k_\perp)}
      {P_{\rm HI-HI}(k_\parallel,k_\perp)+N^{\rm HI}},
    \end{equation}
    where $N^{\rm HI}$ is the 21cm noise power spectrum.

    \begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{sigma_photo.png}
      \caption{}\label{fig:sigma}
    \end{figure}
    To estimate the uncertainty $\sigma_\parallel$ in Eq. \ref{eq:final_fisher}
    we consider the following specifications:
    \begin{itemize}
      \item For intensity mapping (this affects both $P_{\rm HI-HI}$ and $N^{\rm HI}$):
            $D_{\rm dish}=15\,{\rm m}$, $N_{\rm dish}=200$,
            $t_{\rm total}=10000\,{\rm h}$, $f_{\rm sky}=0.5$. $\bar{T}_{\rm HI}$
            and $b_{\rm HI}$ given by \cite{Bull:2014rha}.
      \item For LSST galaxies we assume a Gaussian photometric redshift uncertainty
            $\sigma_z=0.03(1+z)$ (which translates into $\sigma_{\rm ph}$ as
            $\sigma_{\rm ph}=c\sigma_z/H(z)$), and a galaxy bias given by
            \cite{Alonso:2015sfa}.
    \end{itemize}

    Figure \ref{fig:sigma} shows the predictions for $\sigma_\parallel$ for different
    cases. The red solid line shows the photometric contribution alone, the green
    lines show the contribution from clustering alone and the blue lines show
    the combined uncertainties (given in Eq. \ref{eq:final_fisher} as the inverse
    sum of inverses). Three cases are shown depending on the maximum Fourier mode
    $k_{\rm max}$ included in the analysis (this method cannot be used on scales
    where the various power spectra are poorly known):
    \begin{itemize}
      \item Optimistic (solid lines): $k_{\rm max}=0.2\,(1+z)\,h/{\rm Mpc}$.
      \item Fiducial (dashed lines): $k_{\rm max}=0.1\,(1+z)\,h/{\rm Mpc}$.
      \item Pessimistic (dot-dashed lines): $k_{\rm max}=0.05\,(1+z)\,h/{\rm Mpc}$.
    \end{itemize}

    \begin{figure}
      \centering
      \includegraphics[width=0.7\textwidth]{los.png}\caption{}\label{fig:sim}
    \end{figure}
    According to Figure \ref{fig:sigma} it would in principle be possible to improve
    the photometric redshift uncertainties at low redshifts down from $O(100)\,
    {\rm Mpc}/h$ to $O(10)\,{\rm Mpc}/h$ using clustering information. While this
    improvement is astonishing, it is probably unrealistic. Even without including
    non-linear scales, the cosmological matter density field exhibits structures on
    scales much smaller than the initial photo-$z$ uncertainties of
    $O(100)\,{\rm Mpc}/h$. Since the method of clustering redshifts can be thought
    of as assigning to each galaxy the redshift of any prominent structure found
    along the line of sight, we can therefore expect that the posterior distribution
    for individual galaxies will be highly multimodal. This case cannot be well
    described by a Fisher-matrix approximation, in which the likelihood is only
    evaluated in the neighborhood of its maximum. Thus, in a way, the estimate
    shown in Figure \ref{fig:sigma} actually shows the expected width of each
    individual mode in the posterior distribution, rather than the overall
    uncertainty in $\xpr$. We illustrate this in Fig. \ref{fig:sim}. This figure
    shows the distribution of neutral hydrogen along a line of sight of transverse size
    $\Delta x_\perp\sim2\,{\rm Mpc}/h$ in an N-body simulation. The comoving
    width of the slice shown in the figure corresponds to $\sim300\,{\rm Mpc}/h$.
    A large number of structures can be found in this slice (and even more would
    be found when convolved with the large SKA beam). We describe the effect of this
    multi-modality in the next sections.

\section{Individual redshift estimation}
  \begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{pdf_1d.png}
    \caption{}\label{fig:pdf_1d}
  \end{figure}
  The formalism described in the previous section uses the full clustering information
  of a sample of galaxies with an overlaping HI map to evaluate the joint posterior
  distribution of all the galaxy redshifts. As we have seen, this is an interesting
  problem from the point of view of data analysis which could potentially improve the
  redshift measurements and which can realistically be solved using efficient sampling
  methods. We have also seen that the resulting joint distribution will potentially be
  multi-modal and show tight correlations between different galaxies. However, this
  formalism is the most general and optimal way of estimating galaxy redshifts in
  the presence of overlapping datasets with good radial information.
  
  In this section we present a simpler (but non-optimal) method, based on inferring 
  the redshifts of individual galaxies from the measured density field along the line
  of sight (i.e. ignoring the full clustering information between the full galaxy sample
  and the HI field).  
  In this case we want to calculate the probability distribution for the redshift of a
  single galaxy given the data:
  \begin{equation}
    p(z|\dhi,\hat{n},m)=p(z|\dhi,\hat{n}) p(m|z)/p(m),
  \end{equation}
  where, as before, we have separated the information coming from magnitudes and
  clustering. We can see that, as before, the information from the photometry $m$
  functions as a prior on $p(z|\dhi,\hat{n})$. For the moment let us focus on
  $p(z|\dhi,\hat{n})$. First, notice that we can read this as $p(z|\dhi(\hat{n}))$,
  the probability for $z$ given the measured ${\rm HI}$ density along the same line
  of sight. On the other hand, the galaxy redshift distribution is determined by
  the true galaxy density field $\delta_g$, which we can consider $\dhi$ to be a
  noisy measurement of. We must therefore sum over all
  realizations of $\delta_g$ compatible with $\dhi$:
  \begin{equation}\label{eq:single_1}
    p(z|\dhi)=\int \mathcal{D}\delta_g\,p(z|\delta_g,\dhi)\,p(\delta_g|\dhi).
  \end{equation}
  Now, since $\delta_{\rm HI}$ is just a noisy measurement of $\delta_g$, we can
  write $p(z|\delta_g,\delta_{\rm HI})\equiv p(z|\delta_g)$. Since the frequentist
  probability distribution for the galaxy redshifts is just proportional to the
  galaxy density field, we can then write $p(z|\delta_g)\propto\rho_g\propto(1+\delta_g)$,
  in which case the conditional distribution in Eq. \ref{eq:single_1} reads
  \begin{align}
    p(z|\dhi)&\propto\int \mathcal{D}\delta_g(1+\delta_g)\,p(\delta_g|\dhi)\\
             &\equiv(1+\langle\delta_g|\dhi\rangle)
  \end{align}

  For Gaussian random fields, it is easy to show that the mean density field
  conditional on the measured values $\delta_{\rm HI}$,
  $\langle\delta_g|\dhi\rangle$, is given by the Wiener-deconvolved overdensity:
  \begin{equation}
    \langle\delta_g|\dhi\rangle=\hat{C}_{g,{\rm HI}}\,
    \hat{C}_{{\rm HI},{\rm HI}}^{-1}\,\dhi,
  \end{equation}
  where $\hat{C}_{a,b}\equiv\langle\delta_a\delta_b^T\rangle$ is the covariance matrix
  between two fields (understood as vectors in this notation). This is more easily
  written in Fourier space
  \begin{equation}
    \left.\langle\delta_g|\dhi\rangle\right|_{\bf k}=\frac{P_{{\rm HI}-g}({\bf k})}
    {P_{{\rm HI}-{\rm HI}}({\bf k})+N_{\rm HI}(\bf k)}\dhi({\bf k}).
  \end{equation}
  
  The process to estimate the redshift distribution for individual galaxies, given
  a measurement of $\delta_{\rm HI}$ is then relatively straightforward:
  \begin{enumerate}
    \item Compute the Wiener-filtered overdensity field
          $\langle\delta_g|\delta_{\rm HI}\rangle$.
    \item Evaluate this field along the line of sight of each galaxy in the sample.
    \item Multiply this ``clustering likelihood'' by the photometric redshift prior
          $p(m|z)$ and normalize the resulting distribution to unity.
  \end{enumerate}

  See an example of this in Fig \ref{fig:pdf_1d}.

  Fisher-matrix estimate of the width of this distribution:
  \begin{equation}
   \frac{1}{\sigma_\parallel^2}=\frac{1}{\sigma_{\rm ph}^2}+
   \left[4\pi\int_{0}^\infty dk_\parallel \left[\frac{k_\parallel}{2\pi}\right]^4\int_0^\infty
   dk_\perp\,k_\perp
   \frac{P_{{\rm HI-HI}}(k_\parallel,k_\perp)P_{g-g}(k_\parallel,k_\perp)}
   {P_{\rm HI-HI}(k_\parallel,k_\perp))+N_{\rm HI}}\right]^{1/2}
  \end{equation}

  
\appendix  
\section{Fisher matrix formalism} \label{app:fisher}
  In order to compute a Fisher-matrix approximation to the expected uncertainties
  in the galaxy radial positions, we start by expanding the log-posterior
  (Eq. \ref{eq:logpos}) to second order around the true value of the radial positions,
  $\xpr^*$, which we assume correspond to the maximum likelihood:
  \begin{equation}
    \mathcal{L}(\{\xpr^p\})\simeq\mathcal{L}(\xpr^*)+
    \sum_{p,q}F_{pq}(\xpr^p-\xpr^{p*})(\xpr^q-\xpr^{q*}),
  \end{equation}
  where we have defined the Fisher matrix $F_{pq}$
  \begin{equation}
    F_{pq}\equiv\frac{1}{2}\left.\frac{\partial^2\mathcal{L}}
    {\partial\xpr^p\partial\xpr^q}\right|_*,
  \end{equation}
  which can be interpreted as an optimistic estimate of the inverse covariance
  matrix of all the redshift measurements.

  Using the derivatives of $\delta_g$ with respect to the galaxy coordinates:
  \begin{align}
    &\frac{\partial\delta_g({\bf k})}{\partial\xpr^p}=ik_\parallel
     \frac{\tilde{W}}{N_g}e^{i{\bf k}{\bf x}^p}\equiv ik_\parallel W_p,\\
    &\frac{\partial^2\delta_g({\bf k})}{\partial\xpr^p\partial\xpr^q}=
     -\delta_{pq}k^2_\parallel W_p,
  \end{align}
  it is easy to compute the Hessian of $\mathcal{L}$:
  \begin{align}
    &\frac{\partial\mathcal{L}}{\partial \xpr^p}=2
     \left\{\frac{(\xpr^p-\overline{\xpr}^p)}{\sigma_{\rm ph}^2}
     -\sum_{\bf k}\frac{ik_\parallel\epsilon_{\bf k}}
     {2\sigma_g({\bf k})(1-\epsilon^2_{\bf k})}\left(
     \left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-
     \epsilon_{\bf k}\frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]^*W_p-
     \left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-\epsilon_{\bf k}
     \frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]W_p^*\right)\right\}\\
    &F_{pq}\equiv\frac{1}{2}\frac{\partial^2\mathcal{L}}{\partial\xpr^p\partial
     \xpr^q}=\frac{\delta_{pq}}{\sigma_{\rm ph}^2}
     +\sum_{\bf k}\frac{k^2_\parallel\epsilon_{\bf k}}{\sigma_g({\bf k})
     (1-\epsilon_{\bf k}^2)}
     {\rm Re}\left(\left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-
     \epsilon_{\bf k}\frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]^*
     W_p\delta_{pq}+\frac{\epsilon_{\bf k}}{\sigma_g({\bf k})}W_q^*W_p\right).
  \end{align}

  Let us now sum over all the components of the Fisher matrix (without worrying too
  much about the meaning of the resulting quantity for the moment). Using the
  expression for $\delta_g$ in terms of $W_p$ we obtain
  \begin{equation}
    \sum_{p,q}^{N_g}F_{pq}=\frac{N_g}{\sigma_{\rm ph}^2}+
    \sum_{\bf k}\frac{k_\parallel^2\epsilon_{\bf k}}{1-\epsilon_{\bf k}^2}
    \frac{{\rm Re}\left(\dhi({\bf k})\delta_g({\bf k})\right)}
    {\sigma_{\rm HI}({\bf k})\sigma_g}.
  \end{equation}
  Averaging then over all possible realizations of the density field this becomes:
  \begin{equation}\label{eq:sumfisher}
    \left\langle\sum_{p,q}^{N_g}F_{pq}\right\rangle=
    N_g\left[\frac{1}{\sigma_{\rm ph}^2}+\int \frac{dk^3}{(2\pi)^3}
    \frac{k_\parallel^2\epsilon^2_{\bf k}}{\bar{n}(1-\epsilon_{\bf k}^2)}\right],
  \end{equation}
  where we have used
  \begin{equation}
    \sum_{\bf k}\longrightarrow\left(\frac{L}{2\pi}\right)^3\int dk^3,
    \hspace{12pt}\frac{N_g}{V}\equiv\frac{1}{\bar{n}}.
  \end{equation}

  Now, what is the meaning of the quantity we have just calculated? Consider first a
  measurement of $N$ quantities $q_i$, $i\in\{1,...,N\}$, with a covariance matrix
  $\hat{C}\equiv\langle{\bf q}{\bf q}^T\rangle$. It is easy to show that the
  inverse-variance weighted average of all this quantities, and its variance,
  are given by
  \begin{align}
    \bar{q}\equiv\frac{\sum_i(\hat{C}^{-1}\cdot{\bf q})_i}
    {\sum_{i,j}\hat{C}^{-1}_{ij}},\hspace{12pt}
    [{\rm Var}(\bar{q})]^{-1}=\sum_{ij}\hat{C}^{-1}_{ij}=\sum_{ij}\hat{F}_{ij}.
  \end{align}
  Thus we can interpret $\sum_{p,q}F_{pq}$ as the {\sl uncertainty in the mean
  radial position} of all the galaxies. Then, under the (false) assumption that all
  the $\xpr$s are uncorrelated, the typical uncertainty in $\xpr$ could be
  estimated as
  \begin{equation}
    \frac{1}{{\rm Var}(\xpr)}\simeq\frac{1}{N_g}\sum_{p,q}F_{p,q}=
    \frac{1}{\sigma_{\rm ph}^2}+\int \frac{dk^3}{(2\pi)^3}
    \frac{k_\parallel^2\epsilon^2_{\bf k}}{\bar{n}(1-\epsilon_{\bf k}^2)}.
  \end{equation}
  In reality, as the number density of galaxies grows, the redshift measurements
  of nearby galaxies become more tightly correlated. This is the reason why, in
  the limit $\bar{n}\rightarrow\infty$, Equation \ref{eq:sumfisher} tends to $0$:
  in the limit of an infinite number of galaxies, each galaxy carries a negligible
  amount of information regarding their mean radial position, due to their tight
  clustering correlation with the rest.

  Thus, in order to estimate the typical uncertainty on $\xpr$ for individual
  galaxies, we must instead take the limit $\bar{n}\rightarrow0$ in Eq. \ref{eq:sumfisher}.
  This corresponds to the limit where the clustering redshifts are assigned solely
  on the basis of the local density field described by $\dhi$, and not on the
  clustering of each galaxy with respect to other galaxies. In order to take
  this limit safely we must first identify the factor $1/\bar{n}$ with the noise term for
  the galaxy density autocorrelation (i.e. Poisson noise). In that case, the limit
  $\bar{n}\rightarrow0$ of Eq. \ref{eq:sumfisher} yields an estimate of the
  uncertainty in the clustering redshifts of individual galaxies, which is given by:
  \begin{equation}\boxed{
    \frac{1}{\sigma_\parallel^2}=\lim_{\bar{n}\rightarrow0}\frac{1}{N_g}
    \sum_{p,q}^{N_g}F_{pq}=
    \frac{1}{\sigma_{\rm ph}^2}+2\int_0^\infty dk_\parallel
    \left[\frac{k_\parallel}{2\pi}\right]^2\int_0^\infty dk_\perp k_\perp
    \frac{P_{\rm HI-HI}(k_\parallel,k_\perp)P_{g-g}(k_\parallel,k_\perp)}
    {P_{\rm HI-HI}(k_\parallel,k_\perp)+N^{\rm HI}},}
  \end{equation}
  where $N^{\rm HI}$ is the 21cm noise power spectrum.

\appendix  
\section{Fisher matrix formalism} \label{app:fisher}
  In order to compute a Fisher-matrix approximation to the expected uncertainties
  in the galaxy radial positions, we start by expanding the log-posterior
  (Eq. \ref{eq:logpos}) to second order around the true value of the radial positions,
  $\xpr^*$, which we assume correspond to the maximum likelihood:
  \begin{equation}
    \mathcal{L}(\{\xpr^p\})\simeq\mathcal{L}(\xpr^*)+
    \sum_{p,q}F_{pq}(\xpr^p-\xpr^{p*})(\xpr^q-\xpr^{q*}),
  \end{equation}
  where we have defined the Fisher matrix $F_{pq}$
  \begin{equation}
    F_{pq}\equiv\frac{1}{2}\left.\frac{\partial^2\mathcal{L}}
    {\partial\xpr^p\partial\xpr^q}\right|_*,
  \end{equation}
  which can be interpreted as an optimistic estimate of the inverse covariance
  matrix of all the redshift measurements.

  Using the derivatives of $\delta_g$ with respect to the galaxy coordinates:
  \begin{align}
    &\frac{\partial\delta_g({\bf k})}{\partial\xpr^p}=ik_\parallel
     \frac{\tilde{W}}{N_g}e^{i{\bf k}{\bf x}^p}\equiv ik_\parallel W_p,\\
    &\frac{\partial^2\delta_g({\bf k})}{\partial\xpr^p\partial\xpr^q}=
     -\delta_{pq}k^2_\parallel W_p,
  \end{align}
  it is easy to compute the Hessian of $\mathcal{L}$:
  \begin{align}
    &\frac{\partial\mathcal{L}}{\partial \xpr^p}=2
     \left\{\frac{(\xpr^p-\overline{\xpr}^p)}{\sigma_{\rm ph}^2}
     -\sum_{\bf k}\frac{ik_\parallel\epsilon_{\bf k}}
     {2\sigma_g({\bf k})(1-\epsilon^2_{\bf k})}\left(
     \left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-
     \epsilon_{\bf k}\frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]^*W_p-
     \left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-\epsilon_{\bf k}
     \frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]W_p^*\right)\right\}\\
    &F_{pq}\equiv\frac{1}{2}\frac{\partial^2\mathcal{L}}{\partial\xpr^p\partial
     \xpr^q}=\frac{\delta_{pq}}{\sigma_{\rm ph}^2}
     +\sum_{\bf k}\frac{k^2_\parallel\epsilon_{\bf k}}{\sigma_g({\bf k})
     (1-\epsilon_{\bf k}^2)}
     {\rm Re}\left(\left[\frac{\dhi({\bf k})}{\sigma_{\rm HI}({\bf k})}-
     \epsilon_{\bf k}\frac{\delta_g({\bf k})}{\sigma_g({\bf k})}\right]^*
     W_p\delta_{pq}+\frac{\epsilon_{\bf k}}{\sigma_g({\bf k})}W_q^*W_p\right).
  \end{align}

  Let us now sum over all the components of the Fisher matrix (without worrying too
  much about the meaning of the resulting quantity for the moment). Using the
  expression for $\delta_g$ in terms of $W_p$ we obtain
  \begin{equation}
    \sum_{p,q}^{N_g}F_{pq}=\frac{N_g}{\sigma_{\rm ph}^2}+
    \sum_{\bf k}\frac{k_\parallel^2\epsilon_{\bf k}}{1-\epsilon_{\bf k}^2}
    \frac{{\rm Re}\left(\dhi({\bf k})\delta_g({\bf k})\right)}
    {\sigma_{\rm HI}({\bf k})\sigma_g}.
  \end{equation}
  Averaging then over all possible realizations of the density field this becomes:
  \begin{equation}\label{eq:sumfisher}
    \left\langle\sum_{p,q}^{N_g}F_{pq}\right\rangle=
    N_g\left[\frac{1}{\sigma_{\rm ph}^2}+\int \frac{dk^3}{(2\pi)^3}
    \frac{k_\parallel^2\epsilon^2_{\bf k}}{\bar{n}(1-\epsilon_{\bf k}^2)}\right],
  \end{equation}
  where we have used
  \begin{equation}
    \sum_{\bf k}\longrightarrow\left(\frac{L}{2\pi}\right)^3\int dk^3,
    \hspace{12pt}\frac{N_g}{V}\equiv\frac{1}{\bar{n}}.
  \end{equation}

  Now, what is the meaning of the quantity we have just calculated? Consider first a
  measurement of $N$ quantities $q_i$, $i\in\{1,...,N\}$, with a covariance matrix
  $\hat{C}\equiv\langle{\bf q}{\bf q}^T\rangle$. It is easy to show that the
  inverse-variance weighted average of all this quantities, and its variance,
  are given by
  \begin{align}
    \bar{q}\equiv\frac{\sum_i(\hat{C}^{-1}\cdot{\bf q})_i}
    {\sum_{i,j}\hat{C}^{-1}_{ij}},\hspace{12pt}
    [{\rm Var}(\bar{q})]^{-1}=\sum_{ij}\hat{C}^{-1}_{ij}=\sum_{ij}\hat{F}_{ij}.
  \end{align}
  Thus we can interpret $\sum_{p,q}F_{pq}$ as the {\sl uncertainty in the mean
  radial position} of all the galaxies. Then, under the (false) assumption that all
  the $\xpr$s are uncorrelated, the typical uncertainty in $\xpr$ could be
  estimated as
  \begin{equation}
    \frac{1}{{\rm Var}(\xpr)}\simeq\frac{1}{N_g}\sum_{p,q}F_{p,q}=
    \frac{1}{\sigma_{\rm ph}^2}+\int \frac{dk^3}{(2\pi)^3}
    \frac{k_\parallel^2\epsilon^2_{\bf k}}{\bar{n}(1-\epsilon_{\bf k}^2)}.
  \end{equation}
  In reality, as the number density of galaxies grows, the redshift measurements
  of nearby galaxies become more tightly correlated. This is the reason why, in
  the limit $\bar{n}\rightarrow\infty$, Equation \ref{eq:sumfisher} tends to $0$:
  in the limit of an infinite number of galaxies, each galaxy carries a negligible
  amount of information regarding their mean radial position, due to their tight
  clustering correlation with the rest.

  Thus, in order to estimate the typical uncertainty on $\xpr$ for individual
  galaxies, we must instead take the limit $\bar{n}\rightarrow0$ in Eq. \ref{eq:sumfisher}.
  This corresponds to the limit where the clustering redshifts are assigned solely
  on the basis of the local density field described by $\dhi$, and not on the
  clustering of each galaxy with respect to other galaxies. In order to take
  this limit safely we must first identify the factor $1/\bar{n}$ with the noise term for
  the galaxy density autocorrelation (i.e. Poisson noise). In that case, the limit
  $\bar{n}\rightarrow0$ of Eq. \ref{eq:sumfisher} yields an estimate of the
  uncertainty in the clustering redshifts of individual galaxies, which is given by:
  \begin{equation}\boxed{
    \frac{1}{\sigma_\parallel^2}=\lim_{\bar{n}\rightarrow0}\frac{1}{N_g}
    \sum_{p,q}^{N_g}F_{pq}=
    \frac{1}{\sigma_{\rm ph}^2}+2\int_0^\infty dk_\parallel
    \left[\frac{k_\parallel}{2\pi}\right]^2\int_0^\infty dk_\perp k_\perp
    \frac{P_{\rm HI-HI}(k_\parallel,k_\perp)P_{g-g}(k_\parallel,k_\perp)}
    {P_{\rm HI-HI}(k_\parallel,k_\perp)+N^{\rm HI}},}
  \end{equation}
  where $N^{\rm HI}$ is the 21cm noise power spectrum.
